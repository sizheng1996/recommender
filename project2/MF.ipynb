{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Useful starting lines\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "import csv\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the Data\n",
    "Note that `ratings` is a sparse matrix that in the shape of (num_items, num_users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n",
      "(10000, 1000)\n",
      "r37_c1\n",
      "(37, 1)\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"47b05e70-6076-44e8-96da-2530dc2187de_data_train.csv\"\n",
    "path_submission = \"9b4d32bb-f99a-466f-95a1-0ab80048971c_sample_submission (2).csv\"\n",
    "ratings = load_data(path_dataset)\n",
    "submission = load_submission(path_submission)\n",
    "submission_row_col = submission[0]\n",
    "submission_pos = submission[1]\n",
    "print(ratings.shape)\n",
    "print(submission_pos[0])\n",
    "print(submission_row_col[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot the number of ratings per movie and user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "min # of items per user = 8, min # of users per item = 3.\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings, train, test = split_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=10, p_test=0.1)\n",
    "plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Split the data into a train and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(ratings, num_items_per_user, num_users_per_item,\n",
    "               min_num_ratings, p_test=0.1):\n",
    "    \"\"\"split the ratings to training data and test data.\n",
    "    Args:\n",
    "        min_num_ratings: \n",
    "            all users and items we keep must have at least min_num_ratings per user and per item. \n",
    "    \"\"\"\n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "    \n",
    "    # select user and item based on the condition.\n",
    "    valid_users = np.where(num_items_per_user >= min_num_ratings)[0]\n",
    "    valid_items = np.where(num_users_per_item >= min_num_ratings)[0]\n",
    "    valid_ratings = ratings[valid_items, :][: , valid_users]  \n",
    "    \n",
    "    # init\n",
    "    num_rows, num_cols = valid_ratings.shape\n",
    "    train = sp.lil_matrix((num_rows, num_cols))\n",
    "    test = sp.lil_matrix((num_rows, num_cols))\n",
    "    \n",
    "    print(\"the shape of original ratings. (# of row, # of col): {}\".format(\n",
    "        ratings.shape))\n",
    "    print(\"the shape of valid ratings. (# of row, # of col): {}\".format(\n",
    "        (num_rows, num_cols)))\n",
    "\n",
    "    nz_items, nz_users = valid_ratings.nonzero()\n",
    "    \n",
    "    # split the data\n",
    "    for user in set(nz_users):\n",
    "        # randomly select a subset of ratings\n",
    "        row, col = valid_ratings[:, user].nonzero()\n",
    "        selects = np.random.choice(row, size=int(len(row) * p_test))\n",
    "        residual = list(set(row) - set(selects))\n",
    "\n",
    "        # add to train set\n",
    "        train[residual, user] = valid_ratings[residual, user]\n",
    "\n",
    "        # add to test set\n",
    "        test[selects, user] = valid_ratings[selects, user]\n",
    "\n",
    "    print(\"Total number of nonzero elements in origial data:{v}\".format(v=ratings.nnz))\n",
    "    print(\"Total number of nonzero elements in train data:{v}\".format(v=train.nnz))\n",
    "    print(\"Total number of nonzero elements in test data:{v}\".format(v=test.nnz))\n",
    "    return valid_ratings, train, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "the shape of original ratings. (# of row, # of col): (10000, 1000)\n",
      "the shape of valid ratings. (# of row, # of col): (9648, 996)\n",
      "Total number of nonzero elements in origial data:1176952\n",
      "Total number of nonzero elements in train data:0\n"
     ]
    }
   ],
   "source": [
    "from plots import plot_train_test_data\n",
    "\n",
    "valid_ratings = read_in_train_data(\n",
    "    ratings, num_items_per_user, num_users_per_item, min_num_ratings=0)\n",
    "#plot_train_test_data(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementing Baselines "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the global mean to do the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of baseline using the global mean: [[1.1168889]].\n"
     ]
    }
   ],
   "source": [
    "from helpers import calculate_mse\n",
    "\n",
    "def baseline_global_mean(train, test):\n",
    "    \"\"\"baseline method: use the global mean.\"\"\"\n",
    "    # find the non zero ratings in the train\n",
    "    nonzero_train = train[train.nonzero()]\n",
    "\n",
    "    # calculate the global mean\n",
    "    global_mean_train = nonzero_train.mean()\n",
    "\n",
    "    # find the non zero ratings in the test\n",
    "    nonzero_test = test[test.nonzero()].todense()\n",
    "\n",
    "    # predict the ratings as global mean\n",
    "    mse = calculate_mse(nonzero_test, global_mean_train)\n",
    "    rmse = np.sqrt(1.0 * mse / nonzero_test.shape[1])\n",
    "    print(\"test RMSE of baseline using the global mean: {v}.\".format(v=rmse))\n",
    "\n",
    "baseline_global_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the user means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-35-e59b454e1b89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     24\u001b[0m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"test RMSE of the baseline using the user mean: {v}.\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrmse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mbaseline_user_mean\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "def baseline_user_mean(train, test):\n",
    "    \"\"\"baseline method: use the user means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    num_items, num_users = train.shape\n",
    "\n",
    "    for user_index in range(num_users):\n",
    "        # find the non-zero ratings for each user in the training dataset\n",
    "        train_ratings = train[:, user_index]\n",
    "        nonzeros_train_ratings = train_ratings[train_ratings.nonzero()]\n",
    "        \n",
    "        # calculate the mean if the number of elements is not 0\n",
    "        if nonzeros_train_ratings.shape[0] != 0:\n",
    "            user_train_mean = nonzeros_train_ratings.mean()\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # find the non-zero ratings for each user in the test dataset\n",
    "        test_ratings = test[:, user_index]\n",
    "        nonzeros_test_ratings = test_ratings[test_ratings.nonzero()].todense()\n",
    "        \n",
    "        # calculate the test error \n",
    "        mse += calculate_mse(nonzeros_test_ratings, user_train_mean)\n",
    "    rmse = np.sqrt(1.0 * mse / test.nnz)\n",
    "    print(\"test RMSE of the baseline using the user mean: {v}.\".format(v=rmse))\n",
    "\n",
    "baseline_user_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Use the item means as the prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "test RMSE of the baseline using the item mean: [[1.09234528]].\n"
     ]
    }
   ],
   "source": [
    "def baseline_item_mean(train, test):\n",
    "    \"\"\"baseline method: use item means as the prediction.\"\"\"\n",
    "    mse = 0\n",
    "    num_items, num_users = train.shape\n",
    "    \n",
    "    for item_index in range(num_items):\n",
    "        # find the non-zero ratings for each item in the training dataset\n",
    "        train_ratings = train[item_index, :]\n",
    "        nonzeros_train_ratings = train_ratings[train_ratings.nonzero()]\n",
    "\n",
    "        # calculate the mean if the number of elements is not 0\n",
    "        if nonzeros_train_ratings.shape[0] != 0:\n",
    "            item_train_mean = nonzeros_train_ratings.mean()\n",
    "        else:\n",
    "            continue\n",
    "        \n",
    "        # find the non-zero ratings for each movie in the test dataset\n",
    "        test_ratings = test[item_index, :]\n",
    "        nonzeros_test_ratings = test_ratings[test_ratings.nonzero()].todense()\n",
    "        \n",
    "        # calculate the test error \n",
    "        mse += calculate_mse(nonzeros_test_ratings, item_train_mean)\n",
    "    rmse = np.sqrt(1.0 * mse / test.nnz)\n",
    "    print(\"test RMSE of the baseline using the item mean: {v}.\".format(v=rmse))\n",
    "    \n",
    "baseline_item_mean(train, test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using SGD"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Initialize matrix factorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def init_MF(train, num_features):\n",
    "    \"\"\"init the parameter for matrix factorization.\"\"\"\n",
    "        \n",
    "    num_item, num_user = train.get_shape()\n",
    "\n",
    "    user_features = np.random.rand(num_features, num_user)\n",
    "    item_features = np.random.rand(num_features, num_item)\n",
    "\n",
    "    # start by item features.\n",
    "    item_nnz = train.getnnz(axis=1)\n",
    "    item_sum = train.sum(axis=1)\n",
    "\n",
    "    for ind in range(num_item):\n",
    "        item_features[0, ind] = item_sum[ind, 0] / item_nnz[ind]\n",
    "    return user_features, item_features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute the cost by the method of matrix factorization.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compute_error(data, user_features, item_features, nz):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    mse = 0\n",
    "    for row, col in nz:\n",
    "        item_info = item_features[:, row]\n",
    "        user_info = user_features[:, col]\n",
    "        mse += (data[row, col] - user_info.T.dot(item_info)) ** 2\n",
    "    return np.sqrt(1.0 * mse / len(nz))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict(submission_row_col, user_features, item_features):\n",
    "    \"\"\"compute the loss (MSE) of the prediction of nonzero elements.\"\"\"\n",
    "    predictions = []\n",
    "    for row, col in submission_row_col:\n",
    "        item_info = item_features[:, row-1]\n",
    "        user_info = user_features[:, col-1]\n",
    "        value_pred = user_info.T.dot(item_info)\n",
    "        if value_pred < 1:\n",
    "            value_pred = 1\n",
    "        elif value_pred > 5:\n",
    "            value_pred = 5\n",
    "        else:\n",
    "            value_pred = round(value_pred)\n",
    "        predictions.append(value_pred) \n",
    "    return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n",
      "iter: 0, RMSE on training set: 1.1130575171915063.\n",
      "iter: 1, RMSE on training set: 1.0455547137223289.\n",
      "iter: 2, RMSE on training set: 1.0300334139933955.\n",
      "iter: 3, RMSE on training set: 1.0258046299471988.\n",
      "iter: 4, RMSE on training set: 1.0241446008501607.\n",
      "iter: 5, RMSE on training set: 1.023753058269983.\n",
      "iter: 6, RMSE on training set: 1.0225090994410113.\n",
      "iter: 7, RMSE on training set: 1.0236768957161957.\n",
      "iter: 8, RMSE on training set: 1.0234347347035029.\n",
      "iter: 9, RMSE on training set: 1.022825063235589.\n",
      "iter: 10, RMSE on training set: 1.0229587713945592.\n",
      "iter: 11, RMSE on training set: 1.0225034894256613.\n",
      "iter: 12, RMSE on training set: 1.0233763244132648.\n",
      "iter: 13, RMSE on training set: 1.0227365081232587.\n",
      "iter: 14, RMSE on training set: 1.0230955506874493.\n",
      "iter: 15, RMSE on training set: 1.0226923319696068.\n",
      "iter: 16, RMSE on training set: 1.0228265793667994.\n",
      "iter: 17, RMSE on training set: 1.0228461998728964.\n",
      "iter: 18, RMSE on training set: 1.0227424340863909.\n",
      "iter: 19, RMSE on training set: 1.0228941848321085.\n",
      "RMSE on test data: 1.031543323865774.\n"
     ]
    }
   ],
   "source": [
    "def matrix_factorization_SGD(train, test):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    # define parameters\n",
    "    gamma = 0.01\n",
    "    num_features = 100   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    num_epochs = 20     # number of full passes through the train set\n",
    "    errors = [0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "    nz_row, nz_col = test.nonzero()\n",
    "    nz_test = list(zip(nz_row, nz_col))\n",
    "\n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "        \n",
    "        for d, n in nz_train:\n",
    "            # update W_d (item_features[:, d]) and Z_n (user_features[:, n])\n",
    "            item_info = item_features[:, d]\n",
    "            user_info = user_features[:, n]\n",
    "            err = train[d, n] - user_info.T.dot(item_info)\n",
    "    \n",
    "            # calculate the gradient and update\n",
    "            item_features[:, d] += gamma * (err * user_info - lambda_item * item_info)\n",
    "            user_features[:, n] += gamma * (err * item_info - lambda_user * user_info)\n",
    "\n",
    "        rmse = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"iter: {}, RMSE on training set: {}.\".format(it, rmse))\n",
    "        \n",
    "        errors.append(rmse)\n",
    "\n",
    "    # evaluate the test error\n",
    "    rmse = compute_error(test, user_features, item_features, nz_test)\n",
    "    print(\"RMSE on test data: {}.\".format(rmse))\n",
    "    \n",
    "    # output the resulting matrices\n",
    "    return user_features, item_features    \n",
    "\n",
    "user_features, item_features = matrix_factorization_SGD(train, test)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "learn the matrix factorization using SGD...\n"
     ]
    }
   ],
   "source": [
    "def matrix_factorization_SGD(train):\n",
    "    \"\"\"matrix factorization by SGD.\"\"\"\n",
    "    # define parameters\n",
    "    gamma = 0.01\n",
    "    num_features = 96   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    num_epochs = 20     # number of full passes through the train set\n",
    "    errors = [0]\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init matrix\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # find the non-zero ratings indices \n",
    "    nz_row, nz_col = train.nonzero()\n",
    "    nz_train = list(zip(nz_row, nz_col))\n",
    "\n",
    "    print(\"learn the matrix factorization using SGD...\")\n",
    "    for it in range(num_epochs):        \n",
    "        # shuffle the training rating indices\n",
    "        np.random.shuffle(nz_train)\n",
    "        \n",
    "        # decrease step size\n",
    "        gamma /= 1.2\n",
    "        \n",
    "        for d, n in nz_train:\n",
    "            # update W_d (item_features[:, d]) and Z_n (user_features[:, n])\n",
    "            item_info = item_features[:, d]\n",
    "            user_info = user_features[:, n]\n",
    "            err = train[d, n] - user_info.T.dot(item_info)\n",
    "    \n",
    "            # calculate the gradient and update\n",
    "            item_features[:, d] += gamma * (err * user_info - lambda_item * item_info)\n",
    "            user_features[:, n] += gamma * (err * item_info - lambda_user * user_info)\n",
    "\n",
    "    \n",
    "    # output the resulting matrices\n",
    "    return user_features, item_features    \n",
    "\n",
    "user_features, item_features = matrix_factorization_SGD(ratings)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_pred = predict(submission_row_col, user_features, item_features)\n",
    "create_csv_submission(submission_pos, ratings_pred, \"pred_sgd\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Learn the Matrix Factorization using Alternating Least Squares"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_user_feature(\n",
    "        train, item_features, lambda_user,\n",
    "        nnz_items_per_user, nz_user_itemindices):\n",
    "    \"\"\"update user feature matrix.\"\"\"\n",
    "    num_user = nnz_items_per_user.shape[0]\n",
    "    num_feature = item_features.shape[0]\n",
    "    lambda_I = lambda_user * sp.eye(num_feature)\n",
    "    updated_user_features = np.zeros((num_feature, num_user))\n",
    "\n",
    "    for user, items in nz_user_itemindices:\n",
    "        # extract the columns corresponding to the prediction for given item\n",
    "        M = item_features[:, items]\n",
    "        \n",
    "        # update column row of user features\n",
    "        V = M @ train[items, user]\n",
    "        A = M @ M.T + nnz_items_per_user[user] * lambda_I\n",
    "        X = np.linalg.solve(A, V)\n",
    "        updated_user_features[:, user] = np.copy(X.T)\n",
    "    return updated_user_features\n",
    "\n",
    "def update_item_feature(\n",
    "        train, user_features, lambda_item,\n",
    "        nnz_users_per_item, nz_item_userindices):\n",
    "    \"\"\"update item feature matrix.\"\"\"\n",
    "    num_item = nnz_users_per_item.shape[0]\n",
    "    num_feature = user_features.shape[0]\n",
    "    lambda_I = lambda_item * sp.eye(num_feature)\n",
    "    updated_item_features = np.zeros((num_feature, num_item))\n",
    "\n",
    "    for item, users in nz_item_userindices:\n",
    "        # extract the columns corresponding to the prediction for given user\n",
    "        M = user_features[:, users]\n",
    "        V = M @ train[item, users].T\n",
    "        A = M @ M.T + nnz_users_per_item[item] * lambda_I\n",
    "        X = np.linalg.solve(A, V)\n",
    "        updated_item_features[:, item] = np.copy(X.T)\n",
    "    return updated_item_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'train' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-cf2c161d4bd9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     50\u001b[0m     \u001b[0miter\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0miter\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     51\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 52\u001b[0;31m \u001b[0mALS\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name 'train' is not defined"
     ]
    }
   ],
   "source": [
    "from helpers import build_index_groups\n",
    "\n",
    "\n",
    "def ALS(train, test):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 20   # K in the lecture notes\n",
    "    lambda_user = 0.1\n",
    "    lambda_item = 0.7\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    iter = 0\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # get the number of non-zero ratings for each user and item\n",
    "    nnz_items_per_user, nnz_users_per_item = train.getnnz(axis=0), train.getnnz(axis=1)\n",
    "    \n",
    "    # group the indices by row or column index\n",
    "    nz_train, nz_item_userindices, nz_user_itemindices = build_index_groups(train)\n",
    "\n",
    "    # run ALS\n",
    "    print(\"\\nstart the ALS algorithm...\")\n",
    "    while change > stop_criterion:\n",
    "        print(\"iterations:\",iter)\n",
    "        # update user feature & item feature\n",
    "        user_features = update_user_feature(\n",
    "            train, item_features, lambda_user,\n",
    "            nnz_items_per_user, nz_user_itemindices)\n",
    "        item_features = update_item_feature(\n",
    "            train, user_features, lambda_item,\n",
    "            nnz_users_per_item, nz_item_userindices)\n",
    "\n",
    "        error = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"RMSE on training set: {}.\".format(error))\n",
    "        error_list.append(error)\n",
    "        change = np.fabs(error_list[-1] - error_list[-2])\n",
    "\n",
    "    # evaluate the test error\n",
    "    nnz_row, nnz_col = test.nonzero()\n",
    "    nnz_test = list(zip(nnz_row, nnz_col))\n",
    "    rmse = compute_error(test, user_features, item_features, nnz_test)\n",
    "    print(\"test RMSE after running ALS: {v}.\".format(v=rmse))\n",
    "    \n",
    "\n",
    "ALS(train, test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "start the ALS algorithm...\n",
      "RMSE on training set: 1.2787824602109301.\n",
      "1 1.2787824602109301\n",
      "RMSE on training set: 1.146811185852592.\n",
      "2 0.1319712743583381\n",
      "RMSE on training set: 1.0947953382773847.\n",
      "3 0.052015847575207275\n",
      "RMSE on training set: 1.0689087352232427.\n",
      "4 0.025886603054142032\n",
      "RMSE on training set: 1.0542636128968312.\n",
      "5 0.014645122326411464\n",
      "RMSE on training set: 1.0452777730877794.\n",
      "6 0.008985839809051877\n",
      "RMSE on training set: 1.039454066081899.\n",
      "7 0.0058237070058804186\n",
      "RMSE on training set: 1.0355324731334405.\n",
      "8 0.003921592948458397\n",
      "RMSE on training set: 1.0328185191278698.\n",
      "9 0.002713954005570729\n",
      "RMSE on training set: 1.0309027332107374.\n",
      "10 0.0019157859171323732\n",
      "RMSE on training set: 1.029530645373123.\n",
      "11 0.001372087837614444\n",
      "RMSE on training set: 1.0285374295383853.\n",
      "12 0.0009932158347376596\n",
      "RMSE on training set: 1.027812788865275.\n",
      "13 0.0007246406731102883\n",
      "RMSE on training set: 1.0272810073870509.\n",
      "14 0.0005317814782241914\n",
      "RMSE on training set: 1.026889064531068.\n",
      "15 0.00039194285598287415\n",
      "RMSE on training set: 1.026599257343589.\n",
      "16 0.0002898071874790631\n",
      "RMSE on training set: 1.0263844569561034.\n",
      "17 0.00021480038748555863\n",
      "RMSE on training set: 1.0262249663338594.\n",
      "18 0.00015949062224396293\n",
      "RMSE on training set: 1.0261063861407533.\n",
      "19 0.00011858019310606593\n",
      "RMSE on training set: 1.0260181352215232.\n",
      "20 8.825091923014838e-05\n"
     ]
    }
   ],
   "source": [
    "from helpers import build_index_groups\n",
    "\n",
    "\n",
    "def ALS(train):\n",
    "    \"\"\"Alternating Least Squares (ALS) algorithm.\"\"\"\n",
    "    # define parameters\n",
    "    num_features = 96   # K in the lecture notes\n",
    "    lambda_user = 0.7\n",
    "    lambda_item = 0.1\n",
    "    stop_criterion = 1e-4\n",
    "    change = 1\n",
    "    error_list = [0, 0]\n",
    "    iter_ = 0\n",
    "    \n",
    "    # set seed\n",
    "    np.random.seed(988)\n",
    "\n",
    "    # init ALS\n",
    "    user_features, item_features = init_MF(train, num_features)\n",
    "    \n",
    "    # get the number of non-zero ratings for each user and item\n",
    "    nnz_items_per_user, nnz_users_per_item = train.getnnz(axis=0), train.getnnz(axis=1)\n",
    "    \n",
    "    # group the indices by row or column index\n",
    "    nz_train, nz_item_userindices, nz_user_itemindices = build_index_groups(train)\n",
    "\n",
    "    # run ALS\n",
    "    print(\"\\nstart the ALS algorithm...\")\n",
    "    while change > stop_criterion:\n",
    "        # update user feature & item feature\n",
    "        user_features = update_user_feature(\n",
    "            train, item_features, lambda_user,\n",
    "            nnz_items_per_user, nz_user_itemindices)\n",
    "        item_features = update_item_feature(\n",
    "            train, user_features, lambda_item,\n",
    "            nnz_users_per_item, nz_item_userindices)\n",
    "        \n",
    "        error = compute_error(train, user_features, item_features, nz_train)\n",
    "        print(\"RMSE on training set: {}.\".format(error))\n",
    "        error_list.append(error)\n",
    "        change = np.fabs(error_list[-1] - error_list[-2])\n",
    "        \n",
    "        iter_ = iter_ + 1\n",
    "        print(iter_,change)\n",
    "\n",
    "    return user_features, item_features\n",
    "\n",
    "user_features, item_features = ALS(ratings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "ratings_pred = predict(submission_row_col, user_features, item_features)\n",
    "create_csv_submission(submission_pos, ratings_pred, \"pred_als\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
