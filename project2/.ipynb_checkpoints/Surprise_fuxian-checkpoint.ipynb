{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.io\n",
    "import scipy.sparse as sp\n",
    "import matplotlib.pyplot as plt\n",
    "from helpers import *\n",
    "import csv\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of items: 10000, number of users: 1000\n"
     ]
    }
   ],
   "source": [
    "from helpers import load_data, preprocess_data\n",
    "\n",
    "path_dataset = \"47b05e70-6076-44e8-96da-2530dc2187de_data_train.csv\"\n",
    "path_submission = \"9b4d32bb-f99a-466f-95a1-0ab80048971c_sample_submission (2).csv\"\n",
    "ratings = load_data(path_dataset)\n",
    "ratings_=ratings.toarray()\n",
    "submission = load_submission(path_submission)\n",
    "submission_row_col = submission[0]\n",
    "submission_pos = submission[1]\n",
    "num_item, num_user = ratings.get_shape()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_nzi = len(ratings.nonzero()[0])\n",
    "nb_nzu = len(ratings.nonzero()[1])\n",
    "\n",
    "users = ratings.nonzero()[1]\n",
    "items = ratings.nonzero()[0]\n",
    "\n",
    "stars = []\n",
    "for i in range(nb_nzi):\n",
    "    stars.append(ratings[items[i],users[i]])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('surprise', 'w') as csvfile:\n",
    "    fieldnames = ['item', 'user','ratings']\n",
    "    writer = csv.DictWriter(csvfile, delimiter=\";\", fieldnames=fieldnames)\n",
    "    for r1, r2,r3 in zip(items, users, stars):\n",
    "        writer.writerow({'item':r1,'user':r2,'ratings':r3})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### mean calculation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_user_mean(train):\n",
    "    #calculate user mean\n",
    "    user_nnz = train.getnnz(axis=0)\n",
    "    user_sum = train.sum(axis=0)\n",
    "    user_mean = np.empty((1, num_user))\n",
    "    for ind in range(num_user):\n",
    "        user_mean[0,ind] = user_sum[0,ind] / user_nnz[ind]\n",
    "    return user_mean\n",
    "def extract_global_mean(train):\n",
    "    # calculate the global mean\n",
    "    nonzero_train = train[train.nonzero()]\n",
    "    global_mean = nonzero_train.mean()\n",
    "    return global_mean\n",
    "user_mean=extract_user_mean(ratings)\n",
    "global_mean=extract_global_mean(ratings)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### baseline estimate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def baseline_estimate(train,lamda_i,lamda_u,epochs):\n",
    "    # set the user and item baselines\n",
    "    bu = np.zeros(num_user)\n",
    "    bi = np.zeros(num_item)    \n",
    "    \n",
    "    # group the indices by row or column index\n",
    "    _, _, nz_user_itemindices = build_index_groups(train)\n",
    "    \n",
    "    #using Alternating Least Squares (ALS)\n",
    "    for iter_ in range(epochs):\n",
    "        for i,i_users in nz_item_userindices:\n",
    "            dev_i = 0\n",
    "            for u in i_users:\n",
    "                dev_i += train[i,u] - global_mean - bu[u]\n",
    "\n",
    "            bi[i] = dev_i / (lamda_i + len(i_users))\n",
    "\n",
    "        for u,u_items in nz_user_itemindices:\n",
    "            dev_u = 0    \n",
    "            for i in u_items:\n",
    "                dev_u += train[i,u] - global_mean - bi[i]\n",
    "\n",
    "            bu[u] = dev_u / (lamda_u + len(u_items))\n",
    "   \n",
    "    return bu,bi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set the parameters\n",
    "lamda_i = 10\n",
    "lamda_u = 15\n",
    "epochs = 10\n",
    "#baseline_estimate\n",
    "bu,bi = baseline_estimate(ratings,lamda_i,lamda_u,epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Similarity with pearson baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "def user_based_similarity_by_pearson_baseline(train,min_support,global_mean, user_biases, item_biases, shrinkage=100):\n",
    "    # set some matrixs\n",
    "    freq = np.zeros((num_user, num_user))# matrix of number of common items\n",
    "    prods = np.zeros((num_user, num_user))# matrix of sum (r_ui - b_ui) * (r_vi - b_vi) for common items\n",
    "    sq_diff_u = np.zeros((num_user,num_user))# matrix of sum (r_ui - b_ui)**2 for common items\n",
    "    sq_diff_v = np.zeros((num_user,num_user))# matrix of sum (r_vi - b_vi)**2 for common items\n",
    "    sim = np.zeros((num_user, num_user))#matrix of similatiries\n",
    "\n",
    "    # Need this because of shrinkage. When pearson coeff is zero when support is 1, so that's OK.\n",
    "    min_support = max(2, min_support)\n",
    "\n",
    "    # group the indices by row or column index\n",
    "    nz_train, nz_item_userindices, nz_user_itemindices = build_index_groups(train)\n",
    "    \n",
    "    for u,items_u in nz_user_itemindices:\n",
    "        sim[u, u] = 1\n",
    "        for v,items_v in nz_user_itemindices[(u+1):]:  \n",
    "            com_items = np.intersect1d(items_u,items_v)\n",
    "            for i in com_items:\n",
    "                freq[u, v] += 1\n",
    "                partial_bias = global_mean + item_biases[i]                \n",
    "                diff_u = (ratings[i,u] - (partial_bias + user_biases[u]))\n",
    "                diff_v = (ratings[i,v] - (partial_bias + user_biases[v]))\n",
    "                prods[u, v] += diff_u * diff_v\n",
    "                sq_diff_u[u, v] += diff_u**2\n",
    "                sq_diff_v[u, v] += diff_v**2\n",
    "            if freq[u, v] < min_support:\n",
    "                sim[u, v] = 0\n",
    "            else:\n",
    "                # calculate the similarity\n",
    "                sim[u, v] = prods[u, v] / (np.sqrt(sq_diff_u[u, v] *\n",
    "                                                       sq_diff_v[u, v]))\n",
    "                # shrunk similarity\n",
    "                sim[u, v] *= (freq[u, v] - 1) / (freq[u, v] - 1 +\n",
    "                                                     shrinkage)\n",
    "\n",
    "            sim[v, u] = sim[u, v]\n",
    "\n",
    "    return sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#set the parameters\n",
    "min_support = 1\n",
    "shrinkage = 1000\n",
    "sim = user_based_similarity_by_pearson_baseline(ratings, min_support, global_mean, bu, bi, shrinkage)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### KNN with means "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def KNN_with_user_means(train,i,u,sim_matrix,k,min_k,user_mean):\n",
    "  \n",
    "    #x, y = self.switch(u, i)\n",
    "\n",
    "    # get k neighbors of users\n",
    "    neighbors=[]\n",
    "    for v in range(num_user):\n",
    "        new_neighbors=(v,sim_matrix[u, v], train[i,v])\n",
    "        neighbors.append(new_neighbors)\n",
    "\n",
    "    # Extract the top-K most-similar ratings\n",
    "    k_neighbors = heapq.nlargest(k, neighbors, key=lambda t: t[1])\n",
    "\n",
    "    #initial setting\n",
    "    est = user_mean[u]\n",
    "    sum_sim = 0\n",
    "    sum_ratings = 0\n",
    "    actual_k = 0\n",
    "\n",
    "    # compute weighted average\n",
    "    for (nb,sim, r) in k_neighbors:\n",
    "        if sim > 0:\n",
    "            sum_sim += sim\n",
    "            sum_ratings += sim * (r - user_mean[nb])\n",
    "            actual_k += 1\n",
    "\n",
    "    if actual_k < min_k:\n",
    "        sum_ratings = 0\n",
    "\n",
    "    try:\n",
    "        est += sum_ratings / sum_sim\n",
    "    except ZeroDivisionError:\n",
    "        pass  # return mean\n",
    "\n",
    "    details = {'actual_k': actual_k}\n",
    "\n",
    "    return est,details"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-115-c9c78897fbed>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[0mu\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcol\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[1;31m# predict with KNN\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mest\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mdetails\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mKNN_with_user_means\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mratings\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mu\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msim\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mk\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmin_k\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0muser_mean\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mT\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     11\u001b[0m     \u001b[1;31m# round value\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-114-b4f5802a4ff6>\u001b[0m in \u001b[0;36mKNN_with_user_means\u001b[1;34m(train, i, u, sim_matrix, k, min_k, user_mean)\u001b[0m\n\u001b[0;32m     23\u001b[0m             \u001b[0msum_sim\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msim\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     24\u001b[0m             \u001b[0msum_ratings\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[0msim\u001b[0m \u001b[1;33m*\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mr\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0muser_mean\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mnb\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 25\u001b[1;33m             \u001b[0mactual_k\u001b[0m \u001b[1;33m+=\u001b[0m \u001b[1;36m1\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     26\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     27\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mactual_k\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mmin_k\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import heapq\n",
    "import math\n",
    "k=300\n",
    "min_k =1\n",
    "pred=[]\n",
    "for row,col in submission_row_col:\n",
    "    i = row-1\n",
    "    u = col-1\n",
    "    # predict with KNN\n",
    "    est,details = KNN_with_user_means(ratings,i,u,sim,k,min_k,user_mean.T)\n",
    "    \n",
    "    # round value    \n",
    "    if est < 1:\n",
    "        est = 1\n",
    "    elif est > 5:\n",
    "        est = 5\n",
    "    else:\n",
    "        est = round(est)\n",
    "        \n",
    "    pred.append(est)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "create_csv_submission(submission_pos, pred, \"pred_fuxian\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
